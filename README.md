
 ğŸ§  AI for Mental Wellness â€” Deep Learning-Based Text Prediction and Assessment

 ğŸ“Œ Overview

This project uses **Natural Language Processing (NLP)** and **Deep Learning** to analyze text data and predict the mental wellness state of an individual.
It identifies patterns and emotions like **Anxiety, Stress, Depression, Suicidal thoughts, Bipolar disorder, Personality disorder,** and **Normal** mental state based on user statements.

 ğŸ¯ Objective

To build a deep learning model that can automatically detect a personâ€™s mental health condition from written text and assist in early emotional assessment.

ğŸ§¾ Dataset

* Total Records:~53,000
* Columns:

  * `statement` â€” Text input expressing a personâ€™s thoughts or feelings
  * `status` â€” Label of the mental wellness class
* Preprocessing Steps:

  * Removed null and noisy records
  * Cleaned unwanted symbols and special characters
  * Retained only 7 valid emotion classes
  * Tokenized, padded, and lowercased all text


ğŸ” Data Visualization & Charts

1. Class Distribution Chart**
   Shows the number of samples for each emotion class. The dataset was slightly imbalanced, with some emotions (like â€œNormalâ€) having more samples than others.

2. **Word Frequency Chart**
   Highlights the most common words in each class â€” for example, â€œsadâ€, â€œaloneâ€, and â€œhurtâ€ were frequent in the Depression class.

3. **Confusion Matrix**
   Displays how well the model predicted each class.
   More diagonal values = higher accuracy for those categories.

4. Accuracy & Loss Curves
   The training and validation accuracy gradually improved, showing the model learned effectively without overfitting.


âš™ï¸ Model Building

Two models were experimented with:

1. DistilBERT (Benchmark Model)

* Pre-trained transformer with ~66M parameters
* Captures bidirectional context from sentences
* Accuracy: ~81â€“90%
* Drawback: Slow inference and needs GPU

 2. BiLSTM (Final Model)

* Architecture:
  `Embedding (100 dim) â†’ BiLSTM (128) â†’ BiLSTM (64) â†’ Dense (128, ReLU) â†’ Dropout â†’ Dense (7, Softmax)`
* Optimizer: Adam
* Loss Function: Categorical Crossentropy
* Used weighted training to handle data imbalance
* Randomly initialized embeddings were learned during training

âœ… Final Accuracy: Around **88â€“90%**
âœ… Model chosen: BiLSTM (for efficiency and good accuracy)

 ğŸ“Š Results Summary

| Model      | Accuracy | Key Feature                     | Drawback                    |
| ---------- | -------- | ------------------------------- | --------------------------- |
| DistilBERT | 81â€“90%   | Strong contextual understanding | Slower inference            |
| BiLSTM     | 88â€“90%   | Lightweight, fast, efficient    | Requires more preprocessing |

 ğŸ’¬ Examples of Each Class

| Class                | Example Statement                                             |
| -------------------- | ------------------------------------------------------------- |
| Anxiety              | â€œoh my goshâ€                                                  |
| Normal               | â€œDreaming of my ex crush, life feels fine.â€                   |
| Depression           | â€œI just want the pain to stop; I feel empty inside.â€          |
| Suicidal             | â€œI feel like life isnâ€™t worth living anymore.â€                |
| Stress               | â€œIâ€™m worried about my health and canâ€™t relax.â€                |
| Bipolar              | â€œOne moment Iâ€™m happy, next Iâ€™m angry for no reason.â€         |
| Personality Disorder | â€œI want to connect with people, but Iâ€™m scared of rejection.â€ |

ğŸ§© Conclusion

The BiLSTM model effectively identifies emotional states from text and can support early mental health awareness and intervention.
It shows how AI and NLP can be used to **analyze emotions, detect distress**, and **support mental wellness** through text-based communication.

ğŸš€ Future Work

* Improve dataset balance using advanced data augmentation
* Implement real-time text emotion detection API
* Deploy as a web app or chatbot for mental wellness support

 *Tech Stack*

* Python
* TensorFlow / Keras
* Pandas, NumPy
* Matplotlib / Seaborn
* NLP techniques (tokenization, padding, embeddings)




